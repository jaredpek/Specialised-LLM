{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a82a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    GenerationConfig,\n",
    "    set_seed,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "set_seed(42)\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783a15a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f50988",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dd8f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be07126f39c94020b3208f035e269aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='microsoft/phi-2'\n",
    "device_map = {\"\": 0}\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=device_map,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090a306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2491af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(model, prompt, max_length=200, tokenizer=tokenizer):\n",
    "    \"\"\"\n",
    "    Generate text using the provided model and prompt\n",
    "    \n",
    "    Args:\n",
    "        model: The language model\n",
    "        prompt: Input text prompt\n",
    "        max_length: Maximum length of generated text\n",
    "        tokenizer: Pre-instantiated tokenizer (uses global tokenizer by default)\n",
    "    \n",
    "    Returns:\n",
    "        List containing generated text\n",
    "    \"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    # Move to same device as model\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=len(inputs[\"input_ids\"][0]) + max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.4,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b89b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT [119]:\n",
      "Compare TCP and UDP. Which one is better for real-time applications like video conferencing and online gaming, and why?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "OUTPUT [1048]:\n",
      "Answer: TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) are two widely used protocols in computer networking. While both have their advantages and disadvantages, TCP is generally considered to be more suitable for real-time applications like video conferencing and online gaming, while UDP is better suited for applications that require faster, more efficient data transfer.\n",
      "\n",
      "TCP is a connection-oriented protocol that ensures reliable data transmission between two devices. It establishes a connection between the sender and receiver, and then breaks it when the data is received. This ensures that all the data is delivered correctly and in the correct order. However, because TCP establishes a connection before transmitting data, it can be slower than other protocols, and it may not be suitable for applications that require real-time data transfer.\n",
      "\n",
      "UDP, on the other hand, is a connectionless protocol that does not establish a connection before transmitting data. This makes it faster and more efficient than TCP, as it\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Compare TCP and UDP. Which one is better for real-time applications like video conferencing and online gaming, and why?\"\n",
    "\n",
    "output = gen(original_model, prompt)\n",
    "\n",
    "print(f'INPUT [{len(prompt)}]:\\n{prompt}')\n",
    "print(100*'-')\n",
    "print(f'OUTPUT [{len(output)}]:\\n{output}')\n",
    "print(100*'-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
